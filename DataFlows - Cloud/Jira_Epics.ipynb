{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/7ft10/JiraExporter/blob/main/DataFlows - Cloud/Jira_Epics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#! Library Import\n",
    "\n",
    "import os \n",
    "import importlib.util\n",
    "\n",
    "if importlib.util.find_spec(\"pandas\") is None:\t\n",
    "\tos.system(\"pip install pandas\")\n",
    "\n",
    "if importlib.util.find_spec(\"dotenv\") is None:\t\n",
    "\tos.system(\"pip install --quiet openai python-dotenv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "#! pandas Config\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "#pd.set_option(\"display.max_rows\", 10)\n",
    "#pd.set_option(\"display.expand_frame_repr\", True)\n",
    "#pd.set_option('display.width', 1000)\n",
    "#pd.options.display.max_seq_items = 200000\n",
    "#pd.options.display.max_rows = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Host: https://jira.budgetdirect.com.au/'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"ValidProjectCategories: 'Client Delivery Project'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Parameters\n",
    "\n",
    "import os \n",
    "import dotenv\n",
    "import importlib.util\n",
    "\n",
    "if importlib.util.find_spec(\"google.colab\") is not None: ## if using google colab\n",
    "    if not os.path.exists('.env'):\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload()\n",
    "        file_name = list(uploaded.keys())[0]\n",
    "        try:\n",
    "            os.rename(file_name, '.env')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "try:\n",
    "    load_dotenv('.env')\n",
    "\n",
    "    Host = os.getenv('SECRETS_HOST') \n",
    "    Username = os.getenv('SECRETS_USERNAME') \n",
    "    Password = os.getenv('SECRETS_PASSWORD') \n",
    "except: \n",
    "    pass \n",
    "\n",
    "if Host is None or Host == \"\":\n",
    "    Host = input(\"Enter Host\")\n",
    "\n",
    "if Username is None or Username == \"\":\n",
    "    Username = input(\"Enter Username\")\n",
    "\n",
    "if Password is None or Password == \"\":\n",
    "    Password = input(\"Enter Password\")\n",
    "\n",
    "display(\"Host: \" + Host)\n",
    "\n",
    "ValidProjectCategories = [\"'Client Delivery Project'\"]\n",
    "display(\"ValidProjectCategories: \" + ','.join(ValidProjectCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Functions\n",
    "\n",
    "import time\n",
    "import base64\n",
    "import pandas as pd\n",
    "import re \n",
    "import requests\n",
    "import warnings\n",
    "from functools import reduce\n",
    "    \n",
    "def _ExpandColumn(self:pd.DataFrame, colName:str, columnsToExpand = [], prefix:str = \"Prefix\", sentenceCase:bool = True) -> pd.DataFrame:\n",
    "    if (prefix == \"Prefix\"):\n",
    "        prefix = colName + \" \"\n",
    "        with warnings.catch_warnings():\n",
    "          warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "          expandedCols = self[colName].apply(lambda x: pd.Series(x).add_prefix(prefix))\n",
    "        columnsToExpand = [prefix + c for c in columnsToExpand]\n",
    "    else:\n",
    "        expandedCols = self[colName].apply(lambda x: pd.Series(x))\n",
    "    \n",
    "    if len(columnsToExpand) > 0:        \n",
    "        expandedCols = expandedCols[columnsToExpand]\n",
    "    \n",
    "    if sentenceCase:\n",
    "        expandedCols.columns = [fnSentenceCase(c) for c in expandedCols.columns] \n",
    "\n",
    "    return pd.concat([self.drop(colName, axis=1), expandedCols], axis=1)\n",
    "\n",
    "pd.DataFrame.expand = _ExpandColumn\n",
    "\n",
    "def fnSentenceCase(s):\n",
    "    s = (' '.join(dict.fromkeys(s.split())))  # remove duplicate words\n",
    "    s = s.replace(\"0\", \"\") # remove \"0\" \n",
    "    s = s.strip()\n",
    "    return ' '.join([x.capitalize() for x in re.sub(r\"([A-Z])\", r\" \\1\", s).split()]) # sentence case\n",
    "\n",
    "def _SentenceCaseColumns(self:pd.DataFrame) -> pd.DataFrame: \n",
    "    self.columns = [fnSentenceCase(c) for c in self.columns] \n",
    "    return self\n",
    "\n",
    "pd.DataFrame.sentence_case_columns = _SentenceCaseColumns\n",
    "\n",
    "def fnGetDefaultHeaders():\n",
    "    return {\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": \"Basic \" + base64.b64encode((Username + \":\" + Password).encode()).decode(),\n",
    "        \"retry-after\": \"120\"\n",
    "    }\n",
    "\n",
    "def fnSearch(jql, fields = None, expand = None):\n",
    "    def ApiCall(startAt) :\n",
    "        url = \"/rest/api/latest/search\"\n",
    "        headers = fnGetDefaultHeaders()\n",
    "        defaultContents = {\n",
    "            \"startAt\": startAt,\n",
    "            \"maxResults\": \"2\",\n",
    "            \"jql\": jql\n",
    "        }\n",
    "        if fields is not None:\n",
    "            defaultContents[\"fields\"] = fields.tolist()\n",
    "        if expand is not None and expand != \"\":\n",
    "            defaultContents[\"expand\"] = expand        \n",
    "        response = requests.post(Host + url, headers = headers, json = defaultContents, verify=False)\n",
    "        return response.json()\n",
    "    values = fnAPI(ApiCall)\n",
    "    if len(values.index) > 1:\n",
    "        return values\n",
    "    else:\n",
    "        None\n",
    "\n",
    "def fnGetIssueTypeFields(IssueTypes) -> pd.DataFrame:\n",
    "    def ApiCall(startAt) :\n",
    "        url = \"rest/api/latest/issue/createmeta\"\n",
    "        headers = fnGetDefaultHeaders()\n",
    "        params = {\n",
    "            \"expand\": \"projects.issuetypes.fields\",\n",
    "            \"projectKeys\": ','.join(fnGetValidProjectKeys()[\"key\"].values),\n",
    "            \"issuetypeNames\": ','.join(IssueTypes).replace(\"'\", \"\")\n",
    "        }\n",
    "        response = requests.get(Host + url, headers = headers, params = params, verify=False)\n",
    "        return response.json()\n",
    "    \n",
    "    df = fnAPI(ApiCall)\n",
    "    df = df.drop([\"expand\"], axis=1)\n",
    "    df = df.explode(\"projects\")\n",
    "    df = df.expand(\"projects\", [], None, False)    \n",
    "    try:\n",
    "        df = df[[\"issuetypes\"]]\n",
    "    except: \n",
    "        raise Exception(\"No issue metadata - check the valid project categories are correct\")\n",
    "    df = df.explode(\"issuetypes\")\n",
    "    df = df.expand(\"issuetypes\", [], None, False)\n",
    "    df = df[[\"fields\"]]\n",
    "    df = df.expand(\"fields\", [], None, False)\n",
    "    df = df.loc[:,~df.columns.duplicated()]\n",
    "\n",
    "    values = []\n",
    "    for x in df.columns:        \n",
    "        try:            \n",
    "            valid:pd.DataFrame = pd.DataFrame( df[~df[x].isnull()] )[[x]].iloc[0].get(0)\n",
    "            values.append({\n",
    "                \"fieldId\": valid['key'] if \"key\" in valid else valid[\"fieldId\"],\n",
    "                \"name\": valid['name'],\n",
    "                \"schema_type\": valid['schema']['type'],\n",
    "                \"required\": valid['required']\n",
    "            })\n",
    "        except:\n",
    "            #display(x)\n",
    "            pass\n",
    "    values.append({ \"fieldId\": 'status', \"name\": 'Status', \"schema_type\": 'string', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'created', \"name\": 'Created', \"schema_type\": 'date', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'updated', \"name\": 'Updated', \"schema_type\": 'date', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'resolution', \"name\": 'Resolution', \"schema_type\": 'string', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'resolutiondate', \"name\": 'Resolution Date', \"schema_type\": 'date', \"required\": False })\n",
    "    values.append({ \"fieldId\": 'lastViewed', \"name\": 'Last Viewed', \"schema_type\": 'date', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'id', \"name\": 'Id', \"schema_type\": 'number', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'key', \"name\": 'Key', \"schema_type\": 'string', \"required\": True })\n",
    "    df = pd.DataFrame(values)\n",
    "    df = df.drop_duplicates().sort_values(\"fieldId\")\n",
    "    return df \n",
    "\n",
    "def fnGetValidProjectKeys() -> pd.DataFrame:\n",
    "    def ApiCall(startAt) :\n",
    "        url = \"/rest/api/latest/project\"\n",
    "        headers = fnGetDefaultHeaders()\n",
    "        params = { }\n",
    "        response = requests.get(Host + url, headers = headers, params = params, verify=False)\n",
    "        return response.json()\n",
    "    df = fnAPI(ApiCall)\n",
    "    df = df.expand(\"projectCategory\")\n",
    "    if 'ValidProjectCategories' in globals() and len(ValidProjectCategories) > 0:\n",
    "        df = df.loc[df['Project Category Name'].isin(ValidProjectCategories) | (\"'\" + df['Project Category Name'] + \"'\").isin(ValidProjectCategories)]\n",
    "    return df[[\"key\"]]\n",
    "\n",
    "def fnAPI(webRequestDelegate, startAt = 0) -> pd.DataFrame:\n",
    "    def flatten_reduce_lambda(frm):\n",
    "        try:\n",
    "            return list(reduce(lambda x, y: x + y, frm, []))         \n",
    "        except:\n",
    "            return list(reduce(lambda x, y: x + y, [frm], [])) \n",
    "    def innerGetResults(webRequestDelegate, startAt = 0):\n",
    "        results = webRequestDelegate(startAt)\n",
    "        if isinstance(results, dict) and \"total\" in results and \"maxResults\" in results:\n",
    "            if startAt + results[\"maxResults\"] < results[\"total\"]:\n",
    "                return [results] + innerGetResults(webRequestDelegate, startAt + results[\"maxResults\"])\n",
    "            else:\n",
    "                return [results]\n",
    "        else:\n",
    "            return [results]\n",
    "    Source = flatten_reduce_lambda(innerGetResults(webRequestDelegate, startAt))\n",
    "    df = pd.DataFrame(Source)\n",
    "    return df\n",
    "\n",
    "def fnGetTimeZoneOffset() -> str:\n",
    "    offset = (time.timezone if (time.localtime().tm_isdst == 0) else time.altzone) / 60 / 60 * -1\n",
    "    return (\"\" if(offset) < 0 else \"+\") + str(int((offset - (offset % 1)))).zfill(2) + \":\" + str(int((offset % 1) * 60)).zfill(2)\n",
    "\n",
    "goldenDF = None\n",
    "globals()['goldenDF'] = None \n",
    "\n",
    "def fnGetGoldenCopy() -> pd.DataFrame:\n",
    "    if 'goldenDF' not in globals() or goldenDF is None: \n",
    "        raise Exception(\"Base data frame not loaded\") \n",
    "    else:\n",
    "        df:pd.DataFrame = goldenDF.copy(deep = True)\n",
    "        if df is None or len(df.index) == 0:\n",
    "            raise Exception (\"No results\")\n",
    "    return df\n",
    "\n",
    "def exit():\n",
    "    class StopExecution(Exception):\n",
    "        def _render_traceback_(self):\n",
    "            []\n",
    "    raise StopExecution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No issue metadata - check the valid project categories are correct",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 88\u001b[0m, in \u001b[0;36mfnGetIssueTypeFields\u001b[1;34m(IssueTypes)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m     df \u001b[39m=\u001b[39m df[[\u001b[39m\"\u001b[39;49m\u001b[39missuetypes\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\n\u001b[0;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m: \n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5937\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['issuetypes'], dtype='object')] are in the [columns]\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m ExpectedIssueTypes \u001b[39m=\u001b[39m [ \u001b[39m\"\u001b[39m\u001b[39mTask\u001b[39m\u001b[39m\"\u001b[39m ]\n\u001b[0;32m      6\u001b[0m JQL \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39missuetype in (\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(ExpectedIssueTypes) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m) and category in (\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(ValidProjectCategories) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m) ORDER BY updatedDate DESC\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m fields \u001b[39m=\u001b[39m fnGetIssueTypeFields(ExpectedIssueTypes)\n\u001b[0;32m     10\u001b[0m goldenDF \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mglobals\u001b[39m()[\u001b[39m'\u001b[39m\u001b[39mgoldenDF\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \n",
      "Cell \u001b[1;32mIn[4], line 90\u001b[0m, in \u001b[0;36mfnGetIssueTypeFields\u001b[1;34m(IssueTypes)\u001b[0m\n\u001b[0;32m     88\u001b[0m     df \u001b[39m=\u001b[39m df[[\u001b[39m\"\u001b[39m\u001b[39missuetypes\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[0;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m: \n\u001b[1;32m---> 90\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo issue metadata - check the valid project categories are correct\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mexplode(\u001b[39m\"\u001b[39m\u001b[39missuetypes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     92\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mexpand(\u001b[39m\"\u001b[39m\u001b[39missuetypes\u001b[39m\u001b[39m\"\u001b[39m, [], \u001b[39mNone\u001b[39;00m, \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mException\u001b[0m: No issue metadata - check the valid project categories are correct"
     ]
    }
   ],
   "source": [
    "#! Jira Issues Capture\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "ExpectedIssueTypes = [ \"Task\" ]\n",
    "JQL = \"issuetype in (\" + ','.join(ExpectedIssueTypes) + \") and category in (\" + ','.join(ValidProjectCategories) + \") ORDER BY updatedDate DESC\"\n",
    "\n",
    "fields = fnGetIssueTypeFields(ExpectedIssueTypes)\n",
    "\n",
    "df = fnSearch(JQL, fields[\"fieldId\"].values)\n",
    "if df is None:\t\n",
    "\tdisplay(\"No results\")\n",
    "\texit()\n",
    "\n",
    "df = df.drop([\"expand\", \"startAt\", \"maxResults\", \"total\"], axis=1)\n",
    "df = df.explode(\"issues\")\n",
    "df = df.expand(\"issues\", [], None, False)\n",
    "df = df.drop([\"expand\", \"self\"], axis=1)\n",
    "df = df.expand(\"fields\", [], None, False)\t\t\n",
    "\n",
    "df = df.rename( columns=dict( zip ( fields.fieldId, fields.name )) )\t\n",
    "\n",
    "df = df.convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "df[\"Id\"] = df[\"Id\"].astype('Int64')\n",
    "\n",
    "goldenDF:pd.DataFrame = df.copy(deep = True)\n",
    "globals()['goldenDF'] = goldenDF # make this globally available \n",
    "\n",
    "df:pd.DataFrame = fnGetGoldenCopy()\n",
    "display(df.dtypes)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                Int64\n",
       "Key                      string[python]\n",
       "Risk Probability                 object\n",
       "Acceptance Criteria              object\n",
       "Change Is                        object\n",
       "Epic Name                string[python]\n",
       "Epic Link                        object\n",
       "Requirement Status               object\n",
       "Description              string[python]\n",
       "T- Shirt Size                    object\n",
       "Resolution Date          string[python]\n",
       "Summary                  string[python]\n",
       "Last Viewed                      object\n",
       "Delivery Teams                   object\n",
       "Created                  string[python]\n",
       "Story Points                    float64\n",
       "Updated                  string[python]\n",
       "Issue Type Id            string[python]\n",
       "Issue Type Name          string[python]\n",
       "Status Id                string[python]\n",
       "Status Name              string[python]\n",
       "Status Category Id                Int64\n",
       "Status Category Name     string[python]\n",
       "Project Id               string[python]\n",
       "Project Name             string[python]\n",
       "Project Category Id      string[python]\n",
       "Project Category Name    string[python]\n",
       "Reporter Key             string[python]\n",
       "Reporter Display Name    string[python]\n",
       "Assignee Key             string[python]\n",
       "Assignee Display Name    string[python]\n",
       "Priority Id              string[python]\n",
       "Priority Name            string[python]\n",
       "Resolution Id            string[python]\n",
       "Resolution Name          string[python]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Issues\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "df:pd.DataFrame = fnGetGoldenCopy()\n",
    "df = df.drop([\"Components\", \"Attachment\", \"Linked Issues\", \"Sprint\", \"Fix versions\", \"Labels\"], axis=1)\n",
    "df = df.expand(\"Issue Type\", [\"id\", \"name\"])\n",
    "df = df.expand(\"Status\", [\"id\", \"name\", \"statusCategory\"]).sentence_case_columns()\n",
    "df = df.expand(\"Status Category\", [\"id\", \"name\"]) \n",
    "df = df.expand(\"Project\", [\"id\", \"name\", \"projectCategory\"]).sentence_case_columns()\n",
    "df = df.expand(\"Project Category\", [\"id\", \"name\"])\n",
    "df = df.expand(\"Reporter\", [\"accountId\", \"displayName\"])\n",
    "df = df.expand(\"Assignee\", [\"accountId\", \"displayName\"])\n",
    "df = df.expand(\"Priority\", [\"id\", \"name\"])\n",
    "df = df.expand(\"Resolution\", [\"id\", \"name\"])\n",
    "df = df.expand(\"Parent\", [\"id\", \"key\"])     \n",
    "df = df.expand(\"Account\", [\"id\", \"value\"])   \n",
    "df = df.expand(\"Tempo Customer\", [\"id\", \"value\"])   \n",
    "\n",
    "df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "df[\"Story Points\"] = df[\"Story Points\"].astype('float')\n",
    "\n",
    "display(df.dtypes)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                           Int64\n",
       "Key                 string[python]\n",
       "Component/s Id      string[python]\n",
       "Component/s Name    string[python]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Components\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "df:pd.DataFrame = fnGetGoldenCopy()\n",
    "df = df[[\"Id\", \"Key\", \"Components\"]]\n",
    "df = df[df[\"Components\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "if df is None or len(df.index) == 0:\t\n",
    "    display(\"No results\")\n",
    "    exit()\n",
    "\n",
    "df = df.explode(\"Components\")\n",
    "df = df.expand(\"Components\", [\"id\", \"name\"])\n",
    "\n",
    "df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "\n",
    "display(df.dtypes)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                      Int64\n",
       "Key                            string[python]\n",
       "Linked Issues Id               string[python]\n",
       "Linked Issues Type                     object\n",
       "Linked Issues Inward Issue             object\n",
       "Linked Issues Outward Issue            object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Linked Issues\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "df:pd.DataFrame = fnGetGoldenCopy()\n",
    "df = df[[\"Id\", \"Key\", \"Linked Issues\"]]\n",
    "df = df[df[\"Linked Issues\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "if df is None or len(df.index) == 0:\t\n",
    "    display(\"No results\")\n",
    "    exit()\n",
    "\n",
    "df = df.explode(\"Linked Issues\")\n",
    "\n",
    "def transform_row(r):  \n",
    "    linkedIssue = r.get(\"Linked Issues\")\n",
    "    inward = \"inwardIssue\" in linkedIssue.keys()\n",
    "    r[\"Type Id\"] = linkedIssue[\"type\"][\"id\"]\n",
    "    r[\"Type Name\"] = linkedIssue[\"type\"][\"name\"]\n",
    "    r[\"Type Direction\"] = \"Inward\" if inward else \"Outward\"\n",
    "    r[\"Type Description\"] = linkedIssue[\"type\"][\"inward\"] if inward else linkedIssue[\"type\"][\"outward\"]\n",
    "    r[\"Linked Issue\"] = linkedIssue[\"inwardIssue\"] if inward else linkedIssue[\"outwardIssue\"]\n",
    "    return r\n",
    "df = df.apply(transform_row, axis=1)\n",
    "\n",
    "df = df.drop([\"Linked Issues\"], axis=1)\n",
    "df = df.expand(\"Linked Issue\", [\"id\", \"key\"])\n",
    "\n",
    "df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "df[\"Type Id\"] = df[\"Type Id\"].astype('Int64')\n",
    "df[\"Linked Issue Id\"] = df[\"Linked Issue Id\"].astype('Int64')\n",
    "\n",
    "display(df.dtypes)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                            Int64\n",
       "Key                                  string[python]\n",
       "Sprint Id                            string[python]\n",
       "Sprint Rapid View Id                 string[python]\n",
       "Sprint State                         string[python]\n",
       "Sprint Name                          string[python]\n",
       "Sprint Start Date         datetime64[ns, UTC+10:00]\n",
       "Sprint End Date           datetime64[ns, UTC+10:00]\n",
       "Sprint Complete Date      datetime64[ns, UTC+10:00]\n",
       "Sprint Activated Date                string[python]\n",
       "Sprint Sequence                      string[python]\n",
       "Sprint Goal                          string[python]\n",
       "Sprint Auto Start Stop               string[python]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Key</th>\n",
       "      <th>Sprint Id</th>\n",
       "      <th>Sprint Rapid View Id</th>\n",
       "      <th>Sprint State</th>\n",
       "      <th>Sprint Name</th>\n",
       "      <th>Sprint Start Date</th>\n",
       "      <th>Sprint End Date</th>\n",
       "      <th>Sprint Complete Date</th>\n",
       "      <th>Sprint Activated Date</th>\n",
       "      <th>Sprint Sequence</th>\n",
       "      <th>Sprint Goal</th>\n",
       "      <th>Sprint Auto Start Stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633036</td>\n",
       "      <td>FLOW-169</td>\n",
       "      <td>5514</td>\n",
       "      <td>1116</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>PPI-FY23Q3-S3</td>\n",
       "      <td>2023-02-06 13:54:00+10:00</td>\n",
       "      <td>2023-02-17 13:54:00+10:00</td>\n",
       "      <td>2023-02-20 14:23:01.092000+10:00</td>\n",
       "      <td>2023-02-06T11:04:28.030+10:00</td>\n",
       "      <td>5514</td>\n",
       "      <td>(1) Finalise and publish changes in response t...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633531</td>\n",
       "      <td>FLOW-175</td>\n",
       "      <td>5495</td>\n",
       "      <td>1116</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>PPI-FY23Q2-S7</td>\n",
       "      <td>2022-12-12 11:00:00+10:00</td>\n",
       "      <td>2022-12-23 17:00:00+10:00</td>\n",
       "      <td>2023-01-09 09:26:05.242000+10:00</td>\n",
       "      <td>2022-12-12T10:51:45.687+10:00</td>\n",
       "      <td>5495</td>\n",
       "      <td>(1) FLOW 69-70; (2) Clouding Atlassian Impleme...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id       Key Sprint Id Sprint Rapid View Id Sprint State  \\\n",
       "0  633036  FLOW-169      5514                 1116       CLOSED   \n",
       "1  633531  FLOW-175      5495                 1116       CLOSED   \n",
       "\n",
       "     Sprint Name         Sprint Start Date           Sprint End Date  \\\n",
       "0  PPI-FY23Q3-S3 2023-02-06 13:54:00+10:00 2023-02-17 13:54:00+10:00   \n",
       "1  PPI-FY23Q2-S7 2022-12-12 11:00:00+10:00 2022-12-23 17:00:00+10:00   \n",
       "\n",
       "              Sprint Complete Date          Sprint Activated Date  \\\n",
       "0 2023-02-20 14:23:01.092000+10:00  2023-02-06T11:04:28.030+10:00   \n",
       "1 2023-01-09 09:26:05.242000+10:00  2022-12-12T10:51:45.687+10:00   \n",
       "\n",
       "  Sprint Sequence                                        Sprint Goal  \\\n",
       "0            5514  (1) Finalise and publish changes in response t...   \n",
       "1            5495  (1) FLOW 69-70; (2) Clouding Atlassian Impleme...   \n",
       "\n",
       "  Sprint Auto Start Stop  \n",
       "0                  false  \n",
       "1                  false  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Sprints\n",
    "\n",
    "from IPython.display import display\n",
    "from pandas.core.dtypes.dtypes import DatetimeTZDtype\n",
    "\n",
    "df:pd.DataFrame = fnGetGoldenCopy()\n",
    "df = df[[\"Id\", \"Key\", \"Sprint\"]]\n",
    "df = df[~df[\"Sprint\"].isna()]\n",
    "\n",
    "if df is None or len(df.index) == 0:\t\n",
    "    display(\"No results\")\n",
    "    exit()\n",
    "\n",
    "df = df.explode(\"Sprint\")\n",
    "df = df.expand(\"Sprint\")\n",
    "\n",
    "df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "\n",
    "df[\"Sprint Start Date\"] = df[\"Sprint Start Date\"].astype(DatetimeTZDtype(\"ns\", fnGetTimeZoneOffset()))\n",
    "df[\"Sprint End Date\"] = df[\"Sprint End Date\"].astype(DatetimeTZDtype(\"ns\", fnGetTimeZoneOffset()))\n",
    "df[\"Sprint Complete Date\"] = df[\"Sprint Complete Date\"].astype(DatetimeTZDtype(\"ns\", fnGetTimeZoneOffset()))\n",
    "\n",
    "display(df.dtypes)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                           Int64\n",
       "Key                                 string[python]\n",
       "Attachment Id                                Int64\n",
       "Attachment Filename                 string[python]\n",
       "Attachment Created       datetime64[ns, UTC+10:00]\n",
       "Attachment Mime Type                string[python]\n",
       "Attachment Size                            float64\n",
       "Attachment Thumbnail                string[python]\n",
       "Attachment Content                  string[python]\n",
       "Attachment Author Key               string[python]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Attachments\n",
    "\n",
    "from IPython.display import display\n",
    "from pandas.core.dtypes.dtypes import DatetimeTZDtype\n",
    "\n",
    "df:pd.DataFrame = fnGetGoldenCopy()\n",
    "df = df[[\"Id\", \"Key\", \"Attachment\"]]\n",
    "df = df[df[\"Attachment\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "if df is None or len(df.index) == 0:\t\n",
    "    display(\"No results\")\n",
    "    exit()\n",
    "\n",
    "df = df.explode(\"Attachment\")\n",
    "df = df.expand(\"Attachment\", [\"id\", \"filename\", \"created\", \"mimeType\", \"size\", \"thumbnail\", \"content\", \"author\"])\n",
    "df = df.expand(\"Attachment Author\", [\"accountId\"])\n",
    "\n",
    "df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "df[\"Attachment Id\"] = df[\"Attachment Id\"].astype('Int64')\n",
    "df[\"Attachment Size\"] = df[\"Attachment Size\"].astype('float64')\n",
    "df[\"Attachment Created\"] = df[\"Attachment Created\"].astype(DatetimeTZDtype(\"ns\", fnGetTimeZoneOffset()))\n",
    "\n",
    "display(df.dtypes)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                             Int64\n",
       "Key                   string[python]\n",
       "Fix Version/s Id               Int64\n",
       "Fix Version/s Name    string[python]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Versions\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "df:pd.DataFrame = fnGetGoldenCopy()\n",
    "df = df[[\"Id\", \"Key\", \"Fix versions\"]]\n",
    "df = df[df[\"Fix versions\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "if df is None or len(df.index) == 0:\t\n",
    "    display(\"No results\")\n",
    "    exit()\n",
    "\n",
    "df = df.explode(\"Fix versions\")\n",
    "df = df.expand(\"Fix versions\", [\"id\", \"name\"])\n",
    "\n",
    "df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "df[\"Fix Versions Id\"] = df[\"Fix Versions Id\"].astype('Int64')\n",
    "\n",
    "display(df.dtypes)\n",
    "display(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
