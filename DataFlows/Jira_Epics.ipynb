{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/7ft10/JiraExporter/blob/main/DataFlows/Jira_Epics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#! Library Import\n",
    "\n",
    "import os \n",
    "import importlib.util\n",
    "\n",
    "if importlib.util.find_spec(\"pandas\") is None:\t\n",
    "\tos.system(\"pip install pandas\")\n",
    "\n",
    "if importlib.util.find_spec(\"dotenv\") is None:\t\n",
    "\t%pip install --quiet openai python-dotenv \n",
    "\tos.system(\"pip install dotenv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "#! pandas Config\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "pd.set_option(\"display.expand_frame_repr\", True)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.max_seq_items = 200000\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Parameters\n",
    "\n",
    "import os \n",
    "import dotenv\n",
    "import importlib.util\n",
    "\n",
    "if importlib.util.find_spec(\"google.colab\") is not None: ## if using google colab\n",
    "    if not os.path.exists('.env'):\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload()\n",
    "        file_name = list(uploaded.keys())[0]\n",
    "        try:\n",
    "            os.rename(file_name, '.env')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "dotenv.load_dotenv('.env')\n",
    "\n",
    "Host = os.getenv('SECRETS_HOST') \n",
    "Username = os.getenv('SECRETS_USERNAME') \n",
    "Password = os.getenv('SECRETS_PASSWORD') \n",
    "ValidProjectCategories = [\"'Customer Delivery Projects'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Functions\n",
    "\n",
    "import base64\n",
    "import pandas as pd\n",
    "import re \n",
    "import requests\n",
    "import warnings\n",
    "from functools import reduce\n",
    "    \n",
    "def _ExpandColumn(self:pd.DataFrame, colName:str, columnsToExpand = [], prefix:str = \"Prefix\", sentenceCase:bool = True) -> pd.DataFrame:\n",
    "    if (prefix == \"Prefix\"):\n",
    "        prefix = colName + \" \"\n",
    "        with warnings.catch_warnings():\n",
    "          warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "          expandedCols = self[colName].apply(lambda x: pd.Series(x).add_prefix(prefix))\n",
    "        columnsToExpand = [prefix + c for c in columnsToExpand]\n",
    "    else:\n",
    "        expandedCols = self[colName].apply(lambda x: pd.Series(x))\n",
    "    \n",
    "    if len(columnsToExpand) > 0:        \n",
    "        expandedCols = expandedCols[columnsToExpand]\n",
    "    \n",
    "    if sentenceCase:\n",
    "        expandedCols.columns = [fnSentenceCase(c) for c in expandedCols.columns] \n",
    "\n",
    "    return pd.concat([self.drop(colName, axis=1), expandedCols], axis=1)\n",
    "\n",
    "pd.DataFrame.expand = _ExpandColumn\n",
    "\n",
    "def fnSentenceCase(s):\n",
    "    s = (' '.join(dict.fromkeys(s.split())))  # remove duplicate words\n",
    "    s = s.replace(\"0\", \"\") # remove \"0\" \n",
    "    s = s.strip()\n",
    "    return ' '.join([x.capitalize() for x in re.sub(r\"([A-Z])\", r\" \\1\", s).split()]) # sentence case\n",
    "\n",
    "def _SentenceCaseColumns(self:pd.DataFrame) -> pd.DataFrame: \n",
    "    self.columns = [fnSentenceCase(c) for c in self.columns] \n",
    "    return self\n",
    "\n",
    "pd.DataFrame.sentence_case_columns = _SentenceCaseColumns\n",
    "\n",
    "def fnGetDefaultHeaders():\n",
    "    return {\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": \"Basic \" + base64.b64encode((Username + \":\" + Password).encode()).decode(),\n",
    "        \"retry-after\": \"120\"\n",
    "    }\n",
    "\n",
    "def fnSearch(jql, fields = None, expand = None):\n",
    "    def ApiCall(startAt) :\n",
    "        url = \"/rest/api/latest/search\"\n",
    "        headers = fnGetDefaultHeaders()\n",
    "        defaultContents = {\n",
    "            \"startAt\": startAt,\n",
    "            \"maxResults\": \"2\",\n",
    "            \"jql\": jql\n",
    "        }\n",
    "        if fields is not None:\n",
    "            defaultContents[\"fields\"] = fields.tolist()\n",
    "        if expand is not None and expand != \"\":\n",
    "            defaultContents[\"expand\"] = expand        \n",
    "\n",
    "        response = requests.post(Host + url, headers = headers, json = defaultContents)\n",
    "        return response.json()\n",
    "    values = fnAPI(ApiCall)\n",
    "    if len(values.index) > 1:\n",
    "        return values\n",
    "    else:\n",
    "        None\n",
    "\n",
    "def fnGetIssueTypeFields(IssueTypes) -> pd.DataFrame:\n",
    "    def ApiCall(startAt) :\n",
    "        url = \"rest/api/latest/issue/createmeta\"\n",
    "        headers = fnGetDefaultHeaders()\n",
    "        params = {\n",
    "            \"expand\": \"projects.issuetypes.fields\",\n",
    "            \"projectKeys\": ','.join(fnGetValidProjectKeys()[\"key\"].values),\n",
    "            \"issuetypeNames\": ','.join(IssueTypes).replace(\"'\", \"\")\n",
    "        }\n",
    "        response = requests.get(Host + url, headers = headers, params = params)\n",
    "        return response.json()\n",
    "    \n",
    "    df = fnAPI(ApiCall)\n",
    "    df = df.drop([\"expand\"], axis=1)\n",
    "    df = df.explode(\"projects\")\n",
    "    df = df.expand(\"projects\", [], None, False)\n",
    "    df = df[[\"issuetypes\"]]\n",
    "    df = df.explode(\"issuetypes\")\n",
    "    df = df.expand(\"issuetypes\", [], None, False)\n",
    "    df = df[[\"fields\"]]\n",
    "    df = df.expand(\"fields\", [], None, False)\n",
    "    df = df.loc[:,~df.columns.duplicated()]\n",
    "\n",
    "    values = []\n",
    "    for x in df.columns:        \n",
    "        try:            \n",
    "            valid = pd.DataFrame( df[~df[x].isnull()] )[[x]].iloc[0].get(0)\n",
    "            values.append({\n",
    "                \"fieldId\": valid['key'],\n",
    "                \"name\": valid['name'],\n",
    "                \"schema_type\": valid['schema']['type'],\n",
    "                \"required\": valid['required']\n",
    "            })\n",
    "        except:\n",
    "            display(x)\n",
    "            pass\n",
    "    values.append({ \"fieldId\": 'status', \"name\": 'Status', \"schema_type\": 'string', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'created', \"name\": 'Created', \"schema_type\": 'date', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'updated', \"name\": 'Updated', \"schema_type\": 'date', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'resolution', \"name\": 'Resolution', \"schema_type\": 'string', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'resolutiondate', \"name\": 'Resolution Date', \"schema_type\": 'date', \"required\": False })\n",
    "    values.append({ \"fieldId\": 'lastViewed', \"name\": 'Last Viewed', \"schema_type\": 'date', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'id', \"name\": 'Id', \"schema_type\": 'number', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'key', \"name\": 'Key', \"schema_type\": 'string', \"required\": True })\n",
    "    df = pd.DataFrame(values)\n",
    "    df = df.drop_duplicates().sort_values(\"fieldId\")\n",
    "    return df \n",
    "\n",
    "def fnGetValidProjectKeys() -> pd.DataFrame:\n",
    "    def ApiCall(startAt) :\n",
    "        url = \"/rest/api/latest/project\"\n",
    "        headers = fnGetDefaultHeaders()\n",
    "        params = { }\n",
    "        response = requests.get(Host + url, headers = headers, params = params)\n",
    "        return response.json()\n",
    "    df = fnAPI(ApiCall)\n",
    "    df = df.expand(\"projectCategory\")\n",
    "    if 'ValidProjectCategories' in globals() and len(ValidProjectCategories) > 0:\n",
    "        df = df.loc[df['Project Category Name'].isin(ValidProjectCategories) | (\"'\" + df['Project Category Name'] + \"'\").isin(ValidProjectCategories)]\n",
    "    return df[[\"key\"]]\n",
    "\n",
    "def fnAPI(webRequestDelegate, startAt = 0) -> pd.DataFrame:\n",
    "    def flatten_reduce_lambda(frm):\n",
    "        try:\n",
    "            return list(reduce(lambda x, y: x + y, frm, []))         \n",
    "        except:\n",
    "            return list(reduce(lambda x, y: x + y, [frm], [])) \n",
    "    def innerGetResults(webRequestDelegate, startAt = 0):\n",
    "        results = webRequestDelegate(startAt)\n",
    "        if isinstance(results, dict) and \"total\" in results and \"maxResults\" in results:\n",
    "            if startAt + results[\"maxResults\"] < results[\"total\"]:\n",
    "                return [results] + innerGetResults(webRequestDelegate, startAt + results[\"maxResults\"])\n",
    "            else:\n",
    "                return [results]\n",
    "        else:\n",
    "            return [results]\n",
    "    Source = flatten_reduce_lambda(innerGetResults(webRequestDelegate, startAt))\n",
    "    df = pd.DataFrame(Source)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                        Int64\n",
       "Key              string[python]\n",
       "Issue Type               object\n",
       "Components               object\n",
       "Description      string[python]\n",
       "                      ...      \n",
       "Due date         string[python]\n",
       "Linked Issues            object\n",
       "Assignee                 object\n",
       "Updated          string[python]\n",
       "Status                   object\n",
       "Length: 44, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Jira Issues Capture\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "ExpectedIssueTypes = [ \"Epic\" ]\n",
    "JQL = \"issuetype in (\" + ','.join(ExpectedIssueTypes) + \") and category in (\" + ','.join(ValidProjectCategories) + \") ORDER BY updatedDate DESC\"\n",
    "\n",
    "fields = fnGetIssueTypeFields(ExpectedIssueTypes)\n",
    "\n",
    "goldenDF = None\n",
    "globals()['goldenDF'] = None \n",
    "\n",
    "df = fnSearch(JQL, fields[\"fieldId\"].values)\n",
    "if df is None:\t\n",
    "\tdisplay(\"No results\")\n",
    "else:\n",
    "\tdf = df.drop([\"expand\", \"startAt\", \"maxResults\", \"total\"], axis=1)\n",
    "\tdf = df.explode(\"issues\")\n",
    "\tdf = df.expand(\"issues\", [], None, False)\n",
    "\tdf = df.drop([\"expand\", \"self\"], axis=1)\n",
    "\tdf = df.expand(\"fields\", [], None, False)\t\t\n",
    "\n",
    "\tdf = df.rename( columns=dict( zip ( fields.fieldId, fields.name )) )\t\n",
    "\n",
    "\tdf = df.convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "\tdf[\"Id\"] = df[\"Id\"].astype('Int64')\n",
    "\n",
    "\tgoldenDF = df.copy(deep = True)\n",
    "\tglobals()['goldenDF'] = goldenDF # make this globally available \n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "\tdisplay(\"Base data frame not loaded\") \n",
    "else:\t\n",
    "\tdisplay(goldenDF.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                Int64\n",
       "Key                      string[python]\n",
       "Description              string[python]\n",
       "Organizations                    object\n",
       "Approvers                        object\n",
       "                              ...      \n",
       "Assignee Display Name    string[python]\n",
       "Priority Id              string[python]\n",
       "Priority Name            string[python]\n",
       "Resolution Id            string[python]\n",
       "Resolution Name          string[python]\n",
       "Length: 49, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Issues\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "   display(\"Base data frame not loaded\") \n",
    "else:\n",
    "   df = goldenDF.copy(deep = True)\n",
    "   if df is None or len(df.index) == 0:\t\n",
    "      display(\"No results\")\n",
    "   else:\n",
    "      df = df.drop([\"Components\", \"Attachment\", \"Linked Issues\", \"Sprint\", \"Fix versions\", \"Labels\"], axis=1)\n",
    "      df = df.expand(\"Issue Type\", [\"id\", \"name\"])\n",
    "      df = df.expand(\"Status\", [\"id\", \"name\", \"statusCategory\"]).sentence_case_columns()\n",
    "      df = df.expand(\"Status Category\", [\"id\", \"name\"]) \n",
    "      df = df.expand(\"Project\", [\"id\", \"name\", \"projectCategory\"]).sentence_case_columns()\n",
    "      df = df.expand(\"Project Category\", [\"id\", \"name\"])\n",
    "      df = df.expand(\"Reporter\", [\"accountId\", \"displayName\"])\n",
    "      df = df.expand(\"Assignee\", [\"accountId\", \"displayName\"])\n",
    "      df = df.expand(\"Priority\", [\"id\", \"name\"])\n",
    "      df = df.expand(\"Resolution\", [\"id\", \"name\"])\n",
    "      #df = df.expand(\"Parent\", [\"id\", \"key\"])     \n",
    "      #df = df.expand(\"Account\", [\"id\", \"value\"])   \n",
    "      #df = df.expand(\"Tempo Customer\", [\"id\", \"value\"])   \n",
    "\n",
    "      df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "      df[\"Story Points\"] = df[\"Story Points\"].astype('float')\n",
    "      \n",
    "      display(df.dtypes)\n",
    "      #display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No results'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Components\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "    display(\"Base data frame not loaded\") \n",
    "else:\n",
    "    df = goldenDF.copy(deep = True)\n",
    "    df = df[[\"Id\", \"Key\", \"Components\"]]\n",
    "    df = df[df[\"Components\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "    if df is None or len(df.index) == 0:\t\n",
    "        display(\"No results\")\n",
    "    else:\n",
    "        df = df.explode(\"Components\")\n",
    "        df = df.expand(\"Components\", [\"id\", \"name\"])\n",
    "\n",
    "        df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "\n",
    "        display(df.dtypes)\n",
    "        #display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No results'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Linked Issues\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "    display(\"Base data frame not loaded\") \n",
    "else:\n",
    "    df = goldenDF.copy(deep = True)\n",
    "    df = df[[\"Id\", \"Key\", \"Linked Issues\"]]\n",
    "    df = df[df[\"Linked Issues\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "    if df is None or len(df.index) == 0:\t\n",
    "        display(\"No results\")\n",
    "    else:\n",
    "        df = df.explode(\"Linked Issues\")\n",
    "        df = df.expand(\"Linked Issues\", [\"id\", \"type\", \"inwardIssue\", \"outwardIssue\"])\n",
    "\n",
    "        df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "\n",
    "        display(df.dtypes)\n",
    "        #display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No results'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Sprints\n",
    "\n",
    "from IPython.display import display\n",
    "from pandas.core.dtypes.dtypes import DatetimeTZDtype\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "    display(\"Base data frame not loaded\") \n",
    "else:\n",
    "    df = goldenDF.copy(deep = True)\n",
    "    df = df[[\"Id\", \"Key\", \"Sprint\"]]\n",
    "    df = df[~df[\"Sprint\"].isna()]\n",
    "\n",
    "    if df is None or len(df.index) == 0:\t\n",
    "        display(\"No results\")\n",
    "    else:\t\t\n",
    "        df = df.explode(\"Sprint\")\n",
    "        df = df.expand(\"Sprint\")\n",
    "\n",
    "        df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "\n",
    "        df[\"Sprint Start Date\"] = df[\"Sprint Start Date\"].astype(DatetimeTZDtype(\"ns\", \"+10:00\"))\n",
    "        df[\"Sprint End Date\"] = df[\"Sprint End Date\"].astype(DatetimeTZDtype(\"ns\", \"+10:00\"))\n",
    "        df[\"Sprint Complete Date\"] = df[\"Sprint Complete Date\"].astype(DatetimeTZDtype(\"ns\", \"+10:00\"))\n",
    "\n",
    "        display(df.dtypes)\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No results'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Attachments\n",
    "\n",
    "from IPython.display import display\n",
    "from pandas.core.dtypes.dtypes import DatetimeTZDtype\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "    display(\"Base data frame not loaded\") \n",
    "else:\n",
    "    df = goldenDF.copy(deep = True)\n",
    "    df = df[[\"Id\", \"Key\", \"Attachment\"]]\n",
    "    df = df[df[\"Attachment\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "    if df is None or len(df.index) == 0:\t\n",
    "        display(\"No results\")\n",
    "    else:\n",
    "        df = df.explode(\"Attachment\")\n",
    "        df = df.expand(\"Attachment\", [\"id\", \"filename\", \"created\", \"mimeType\", \"size\", \"thumbnail\", \"content\", \"author\"])\n",
    "        df = df.expand(\"Attachment Author\", [\"accountId\"])\n",
    "\n",
    "        df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "        df[\"Attachment Id\"] = df[\"Attachment Id\"].astype('Int64')\n",
    "        df[\"Attachment Size\"] = df[\"Attachment Size\"].astype('float64')\n",
    "        df[\"Attachment Created\"] = df[\"Attachment Created\"].astype(DatetimeTZDtype(\"ns\", \"+10:00\"))\n",
    "\n",
    "        display(df.dtypes)\n",
    "        #display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No results'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Versions\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "    display(\"Base data frame not loaded\") \n",
    "else:\n",
    "    df = goldenDF.copy(deep = True)\n",
    "    df = df[[\"Id\", \"Key\", \"Fix versions\"]]\n",
    "    df = df[df[\"Fix versions\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "    if df is None or len(df.index) == 0:\t\n",
    "        display(\"No results\")\n",
    "    else:\n",
    "        df = df.explode(\"Fix versions\")\n",
    "        df = df.expand(\"Fix versions\", [\"id\", \"name\"])\n",
    "\n",
    "        df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "        df[\"Fix Versions Id\"] = df[\"Fix Versions Id\"].astype('Int64')\n",
    "\n",
    "        display(df.dtypes)\n",
    "        #display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
