{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/7ft10/JiraExporter/blob/main/DataFlows/Jira_Epics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#! Library Import\n",
    "\n",
    "import os \n",
    "import importlib.util\n",
    "\n",
    "if importlib.util.find_spec(\"pandas\") is None:\t\n",
    "\tos.system(\"pip install pandas\")\n",
    "\n",
    "if importlib.util.find_spec(\"dotenv\") is None:\t\n",
    "\tos.system(\"pip install --quiet openai python-dotenv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "#! pandas Config\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "#pd.set_option(\"display.max_rows\", 10)\n",
    "#pd.set_option(\"display.expand_frame_repr\", True)\n",
    "#pd.set_option('display.width', 1000)\n",
    "#pd.options.display.max_seq_items = 200000\n",
    "#pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Host: https://jira.budgetdirect.com.au/'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"ValidProjectCategories: 'Portfolio'\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Parameters\n",
    "\n",
    "import os \n",
    "import dotenv\n",
    "import importlib.util\n",
    "\n",
    "if importlib.util.find_spec(\"google.colab\") is not None: ## if using google colab\n",
    "    if not os.path.exists('.env'):\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload()\n",
    "        file_name = list(uploaded.keys())[0]\n",
    "        try:\n",
    "            os.rename(file_name, '.env')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "dotenv.load_dotenv('.env')\n",
    "\n",
    "Host = os.getenv('SECRETS_HOST')\n",
    "Username = os.getenv('SECRETS_USERNAME')\n",
    "Password = os.getenv('SECRETS_PASSWORD')\n",
    "ValidProjectCategories = [\"'Portfolio'\"]\n",
    "\n",
    "if Host is None:\n",
    "    raise Exception(\"Secrets not found\")\n",
    "\n",
    "display(\"Host: \" + Host)\n",
    "display(\"ValidProjectCategories: \" + ','.join(ValidProjectCategories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Functions\n",
    "\n",
    "import base64\n",
    "import pandas as pd\n",
    "import re \n",
    "import requests\n",
    "import warnings\n",
    "from functools import reduce\n",
    "    \n",
    "def _ExpandColumn(self:pd.DataFrame, colName:str, columnsToExpand = [], prefix:str = \"Prefix\", sentenceCase:bool = True) -> pd.DataFrame:\n",
    "    if (prefix == \"Prefix\"):\n",
    "        prefix = colName + \" \"\n",
    "        with warnings.catch_warnings():\n",
    "          warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "          expandedCols = self[colName].apply(lambda x: pd.Series(x).add_prefix(prefix))\n",
    "        columnsToExpand = [prefix + c for c in columnsToExpand]\n",
    "    else:\n",
    "        expandedCols = self[colName].apply(lambda x: pd.Series(x))\n",
    "    \n",
    "    if len(columnsToExpand) > 0:        \n",
    "        expandedCols = expandedCols[columnsToExpand]\n",
    "    \n",
    "    if sentenceCase:\n",
    "        expandedCols.columns = [fnSentenceCase(c) for c in expandedCols.columns] \n",
    "\n",
    "    return pd.concat([self.drop(colName, axis=1), expandedCols], axis=1)\n",
    "\n",
    "pd.DataFrame.expand = _ExpandColumn\n",
    "\n",
    "def fnSentenceCase(s):\n",
    "    s = (' '.join(dict.fromkeys(s.split())))  # remove duplicate words\n",
    "    s = s.replace(\"0\", \"\") # remove \"0\" \n",
    "    s = s.strip()\n",
    "    return ' '.join([x.capitalize() for x in re.sub(r\"([A-Z])\", r\" \\1\", s).split()]) # sentence case\n",
    "\n",
    "def _SentenceCaseColumns(self:pd.DataFrame) -> pd.DataFrame: \n",
    "    self.columns = [fnSentenceCase(c) for c in self.columns] \n",
    "    return self\n",
    "\n",
    "pd.DataFrame.sentence_case_columns = _SentenceCaseColumns\n",
    "\n",
    "def fnGetDefaultHeaders():\n",
    "    return {\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": \"Basic \" + base64.b64encode((Username + \":\" + Password).encode()).decode(),\n",
    "        \"retry-after\": \"120\"\n",
    "    }\n",
    "\n",
    "def fnSearch(jql, fields = None, expand = None):\n",
    "    def ApiCall(startAt) :\n",
    "        url = \"/rest/api/latest/search\"\n",
    "        headers = fnGetDefaultHeaders()\n",
    "        defaultContents = {\n",
    "            \"startAt\": startAt,\n",
    "            \"maxResults\": \"2\",\n",
    "            \"jql\": jql\n",
    "        }\n",
    "        if fields is not None:\n",
    "            defaultContents[\"fields\"] = fields.tolist()\n",
    "        if expand is not None and expand != \"\":\n",
    "            defaultContents[\"expand\"] = expand        \n",
    "        response = requests.post(Host + url, headers = headers, json = defaultContents, verify=False)\n",
    "        return response.json()\n",
    "    values = fnAPI(ApiCall)\n",
    "    if len(values.index) > 1:\n",
    "        return values\n",
    "    else:\n",
    "        None\n",
    "\n",
    "def fnGetIssueTypeFields(IssueTypes) -> pd.DataFrame:\n",
    "    def ApiCall(startAt) :\n",
    "        url = \"rest/api/latest/issue/createmeta\"\n",
    "        headers = fnGetDefaultHeaders()\n",
    "        params = {\n",
    "            \"expand\": \"projects.issuetypes.fields\",\n",
    "            \"projectKeys\": ','.join(fnGetValidProjectKeys()[\"key\"].values),\n",
    "            \"issuetypeNames\": ','.join(IssueTypes).replace(\"'\", \"\")\n",
    "        }\n",
    "        response = requests.get(Host + url, headers = headers, params = params, verify=False)\n",
    "        return response.json()\n",
    "    \n",
    "    df = fnAPI(ApiCall)\n",
    "    df = df.drop([\"expand\"], axis=1)\n",
    "    df = df.explode(\"projects\")\n",
    "    df = df.expand(\"projects\", [], None, False)    \n",
    "    try:\n",
    "        df = df[[\"issuetypes\"]]\n",
    "    except: \n",
    "        raise Exception(\"No issue metadata - check the valid project categories are correct\")\n",
    "    df = df.explode(\"issuetypes\")\n",
    "    df = df.expand(\"issuetypes\", [], None, False)\n",
    "    df = df[[\"fields\"]]\n",
    "    df = df.expand(\"fields\", [], None, False)\n",
    "    df = df.loc[:,~df.columns.duplicated()]\n",
    "\n",
    "    values = []\n",
    "    for x in df.columns:        \n",
    "        try:            \n",
    "            valid:pd.DataFrame = pd.DataFrame( df[~df[x].isnull()] )[[x]].iloc[0].get(0)\n",
    "            values.append({\n",
    "                \"fieldId\": valid['key'] if \"key\" in valid else valid[\"fieldId\"],\n",
    "                \"name\": valid['name'],\n",
    "                \"schema_type\": valid['schema']['type'],\n",
    "                \"required\": valid['required']\n",
    "            })\n",
    "        except:\n",
    "            #display(x)\n",
    "            pass\n",
    "    values.append({ \"fieldId\": 'status', \"name\": 'Status', \"schema_type\": 'string', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'created', \"name\": 'Created', \"schema_type\": 'date', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'updated', \"name\": 'Updated', \"schema_type\": 'date', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'resolution', \"name\": 'Resolution', \"schema_type\": 'string', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'resolutiondate', \"name\": 'Resolution Date', \"schema_type\": 'date', \"required\": False })\n",
    "    values.append({ \"fieldId\": 'lastViewed', \"name\": 'Last Viewed', \"schema_type\": 'date', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'id', \"name\": 'Id', \"schema_type\": 'number', \"required\": True })\n",
    "    values.append({ \"fieldId\": 'key', \"name\": 'Key', \"schema_type\": 'string', \"required\": True })\n",
    "    df = pd.DataFrame(values)\n",
    "    df = df.drop_duplicates().sort_values(\"fieldId\")\n",
    "    return df \n",
    "\n",
    "def fnGetValidProjectKeys() -> pd.DataFrame:\n",
    "    def ApiCall(startAt) :\n",
    "        url = \"/rest/api/latest/project\"\n",
    "        headers = fnGetDefaultHeaders()\n",
    "        params = { }\n",
    "        response = requests.get(Host + url, headers = headers, params = params, verify=False)\n",
    "        return response.json()\n",
    "    df = fnAPI(ApiCall)\n",
    "    df = df.expand(\"projectCategory\")\n",
    "    if 'ValidProjectCategories' in globals() and len(ValidProjectCategories) > 0:\n",
    "        df = df.loc[df['Project Category Name'].isin(ValidProjectCategories) | (\"'\" + df['Project Category Name'] + \"'\").isin(ValidProjectCategories)]\n",
    "    return df[[\"key\"]]\n",
    "\n",
    "def fnAPI(webRequestDelegate, startAt = 0) -> pd.DataFrame:\n",
    "    def flatten_reduce_lambda(frm):\n",
    "        try:\n",
    "            return list(reduce(lambda x, y: x + y, frm, []))         \n",
    "        except:\n",
    "            return list(reduce(lambda x, y: x + y, [frm], [])) \n",
    "    def innerGetResults(webRequestDelegate, startAt = 0):\n",
    "        results = webRequestDelegate(startAt)\n",
    "        if isinstance(results, dict) and \"total\" in results and \"maxResults\" in results:\n",
    "            if startAt + results[\"maxResults\"] < results[\"total\"]:\n",
    "                return [results] + innerGetResults(webRequestDelegate, startAt + results[\"maxResults\"])\n",
    "            else:\n",
    "                return [results]\n",
    "        else:\n",
    "            return [results]\n",
    "    Source = flatten_reduce_lambda(innerGetResults(webRequestDelegate, startAt))\n",
    "    df = pd.DataFrame(Source)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                              Int64\n",
       "Key                    string[python]\n",
       "Issue Type                     object\n",
       "Risk Probability               object\n",
       "Acceptance Criteria            object\n",
       "Component/s                    object\n",
       "Change is                      object\n",
       "Sprint                         object\n",
       "Epic Name              string[python]\n",
       "Epic Link                      object\n",
       "Requirement Status             object\n",
       "Description            string[python]\n",
       "Project                        object\n",
       "T-Shirt Size                   object\n",
       "Fix Version/s                  object\n",
       "Resolution                     object\n",
       "Attachment                     object\n",
       "Resolution Date        string[python]\n",
       "Summary                string[python]\n",
       "Last Viewed                    object\n",
       "Delivery Teams                 object\n",
       "Created                string[python]\n",
       "Reporter                       object\n",
       "Priority                       object\n",
       "Labels                         object\n",
       "Story Points                    Int64\n",
       "Linked Issues                  object\n",
       "Assignee                       object\n",
       "Updated                string[python]\n",
       "Status                         object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Jira Issues Capture\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "ExpectedIssueTypes = [ \"Epic\" ]\n",
    "JQL = \"issuetype in (\" + ','.join(ExpectedIssueTypes) + \") and category in (\" + ','.join(ValidProjectCategories) + \") ORDER BY updatedDate DESC\"\n",
    "\n",
    "fields = fnGetIssueTypeFields(ExpectedIssueTypes)\n",
    "\n",
    "goldenDF = None\n",
    "globals()['goldenDF'] = None \n",
    "\n",
    "df = fnSearch(JQL, fields[\"fieldId\"].values)\n",
    "if df is None:\t\n",
    "\tdisplay(\"No results\")\n",
    "else:\n",
    "\tdf = df.drop([\"expand\", \"startAt\", \"maxResults\", \"total\"], axis=1)\n",
    "\tdf = df.explode(\"issues\")\n",
    "\tdf = df.expand(\"issues\", [], None, False)\n",
    "\tdf = df.drop([\"expand\", \"self\"], axis=1)\n",
    "\tdf = df.expand(\"fields\", [], None, False)\t\t\n",
    "\n",
    "\tdf = df.rename( columns=dict( zip ( fields.fieldId, fields.name )) )\t\n",
    "\n",
    "\tdf = df.convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "\tdf[\"Id\"] = df[\"Id\"].astype('Int64')\n",
    "\n",
    "\tgoldenDF = df.copy(deep = True)\n",
    "\tglobals()['goldenDF'] = goldenDF # make this globally available \n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "\tdisplay(\"Base data frame not loaded\") \n",
    "else:\t\n",
    "\tdisplay(goldenDF.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                Int64\n",
       "Key                      string[python]\n",
       "Risk Probability                 object\n",
       "Acceptance Criteria              object\n",
       "Change Is                        object\n",
       "Epic Name                string[python]\n",
       "Epic Link                        object\n",
       "Requirement Status               object\n",
       "Description              string[python]\n",
       "T- Shirt Size                    object\n",
       "Resolution Date          string[python]\n",
       "Summary                  string[python]\n",
       "Last Viewed                      object\n",
       "Delivery Teams                   object\n",
       "Created                  string[python]\n",
       "Story Points                    float64\n",
       "Updated                  string[python]\n",
       "Issue Type Id            string[python]\n",
       "Issue Type Name          string[python]\n",
       "Status Id                string[python]\n",
       "Status Name              string[python]\n",
       "Status Category Id                Int64\n",
       "Status Category Name     string[python]\n",
       "Project Id               string[python]\n",
       "Project Name             string[python]\n",
       "Project Category Id      string[python]\n",
       "Project Category Name    string[python]\n",
       "Reporter Key             string[python]\n",
       "Reporter Display Name    string[python]\n",
       "Assignee Key             string[python]\n",
       "Assignee Display Name    string[python]\n",
       "Priority Id              string[python]\n",
       "Priority Name            string[python]\n",
       "Resolution Id            string[python]\n",
       "Resolution Name          string[python]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Issues\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "   display(\"Base data frame not loaded\") \n",
    "else:\n",
    "   df = goldenDF.copy(deep = True)\n",
    "   if df is None or len(df.index) == 0:\t\n",
    "      display(\"No results\")\n",
    "   else:\n",
    "      df = df.drop([\"Component/s\", \"Attachment\", \"Linked Issues\", \"Sprint\", \"Fix Version/s\", \"Labels\"], axis=1)\n",
    "      df = df.expand(\"Issue Type\", [\"id\", \"name\"])\n",
    "      df = df.expand(\"Status\", [\"id\", \"name\", \"statusCategory\"]).sentence_case_columns()\n",
    "      df = df.expand(\"Status Category\", [\"id\", \"name\"]) \n",
    "      df = df.expand(\"Project\", [\"id\", \"name\", \"projectCategory\"]).sentence_case_columns()\n",
    "      df = df.expand(\"Project Category\", [\"id\", \"name\"])\n",
    "      df = df.expand(\"Reporter\", [\"key\", \"displayName\"]) #df = df.expand(\"Reporter\", [\"accountId\", \"displayName\"]) \n",
    "      df = df.expand(\"Assignee\", [\"key\", \"displayName\"]) #df = df.expand(\"Assignee\", [\"accountId\", \"displayName\"])\n",
    "      df = df.expand(\"Priority\", [\"id\", \"name\"])\n",
    "      df = df.expand(\"Resolution\", [\"id\", \"name\"])\n",
    "      #df = df.expand(\"Parent\", [\"id\", \"key\"])     \n",
    "      #df = df.expand(\"Account\", [\"id\", \"value\"])   \n",
    "      #df = df.expand(\"Tempo Customer\", [\"id\", \"value\"])   \n",
    "\n",
    "      df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "      df[\"Story Points\"] = df[\"Story Points\"].astype('float')\n",
    "      \n",
    "      display(df.dtypes)\n",
    "      #display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                           Int64\n",
       "Key                 string[python]\n",
       "Component/s Id      string[python]\n",
       "Component/s Name    string[python]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Components\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "    display(\"Base data frame not loaded\") \n",
    "else:\n",
    "    df = goldenDF.copy(deep = True)\n",
    "    df = df[[\"Id\", \"Key\", \"Component/s\"]]\n",
    "    df = df[df[\"Component/s\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "    if df is None or len(df.index) == 0:\t\n",
    "        display(\"No results\")\n",
    "    else:\n",
    "        df = df.explode(\"Component/s\")\n",
    "        df = df.expand(\"Component/s\", [\"id\", \"name\"])\n",
    "\n",
    "        df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "\n",
    "        display(df.dtypes)\n",
    "        #display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                      Int64\n",
       "Key                            string[python]\n",
       "Linked Issues Id               string[python]\n",
       "Linked Issues Type                     object\n",
       "Linked Issues Inward Issue             object\n",
       "Linked Issues Outward Issue            object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Linked Issues\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "    display(\"Base data frame not loaded\") \n",
    "else:\n",
    "    df = goldenDF.copy(deep = True)\n",
    "    df = df[[\"Id\", \"Key\", \"Linked Issues\"]]\n",
    "    df = df[df[\"Linked Issues\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "    if df is None or len(df.index) == 0:\t\n",
    "        display(\"No results\")\n",
    "    else:\n",
    "        df = df.explode(\"Linked Issues\")\n",
    "        df = df.expand(\"Linked Issues\", [\"id\", \"type\", \"inwardIssue\", \"outwardIssue\"])\n",
    "\n",
    "        df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "\n",
    "        display(df.dtypes)\n",
    "        #display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                            Int64\n",
       "Key                                  string[python]\n",
       "Sprint Id                            string[python]\n",
       "Sprint Rapid View Id                 string[python]\n",
       "Sprint State                         string[python]\n",
       "Sprint Name                          string[python]\n",
       "Sprint Start Date         datetime64[ns, UTC+10:00]\n",
       "Sprint End Date           datetime64[ns, UTC+10:00]\n",
       "Sprint Complete Date      datetime64[ns, UTC+10:00]\n",
       "Sprint Activated Date                string[python]\n",
       "Sprint Sequence                      string[python]\n",
       "Sprint Goal                          string[python]\n",
       "Sprint Auto Start Stop               string[python]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Key</th>\n",
       "      <th>Sprint Id</th>\n",
       "      <th>Sprint Rapid View Id</th>\n",
       "      <th>Sprint State</th>\n",
       "      <th>Sprint Name</th>\n",
       "      <th>Sprint Start Date</th>\n",
       "      <th>Sprint End Date</th>\n",
       "      <th>Sprint Complete Date</th>\n",
       "      <th>Sprint Activated Date</th>\n",
       "      <th>Sprint Sequence</th>\n",
       "      <th>Sprint Goal</th>\n",
       "      <th>Sprint Auto Start Stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633036</td>\n",
       "      <td>FLOW-169</td>\n",
       "      <td>5514</td>\n",
       "      <td>1116</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>PPI-FY23Q3-S3</td>\n",
       "      <td>2023-02-06 13:54:00+10:00</td>\n",
       "      <td>2023-02-17 13:54:00+10:00</td>\n",
       "      <td>2023-02-20 14:23:01.092000+10:00</td>\n",
       "      <td>2023-02-06T11:04:28.030+10:00</td>\n",
       "      <td>5514</td>\n",
       "      <td>(1) Finalise and publish changes in response t...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633531</td>\n",
       "      <td>FLOW-175</td>\n",
       "      <td>5495</td>\n",
       "      <td>1116</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>PPI-FY23Q2-S7</td>\n",
       "      <td>2022-12-12 11:00:00+10:00</td>\n",
       "      <td>2022-12-23 17:00:00+10:00</td>\n",
       "      <td>2023-01-09 09:26:05.242000+10:00</td>\n",
       "      <td>2022-12-12T10:51:45.687+10:00</td>\n",
       "      <td>5495</td>\n",
       "      <td>(1) FLOW 69-70; (2) Clouding Atlassian Impleme...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id       Key Sprint Id Sprint Rapid View Id Sprint State  \\\n",
       "0  633036  FLOW-169      5514                 1116       CLOSED   \n",
       "1  633531  FLOW-175      5495                 1116       CLOSED   \n",
       "\n",
       "     Sprint Name         Sprint Start Date           Sprint End Date  \\\n",
       "0  PPI-FY23Q3-S3 2023-02-06 13:54:00+10:00 2023-02-17 13:54:00+10:00   \n",
       "1  PPI-FY23Q2-S7 2022-12-12 11:00:00+10:00 2022-12-23 17:00:00+10:00   \n",
       "\n",
       "              Sprint Complete Date          Sprint Activated Date  \\\n",
       "0 2023-02-20 14:23:01.092000+10:00  2023-02-06T11:04:28.030+10:00   \n",
       "1 2023-01-09 09:26:05.242000+10:00  2022-12-12T10:51:45.687+10:00   \n",
       "\n",
       "  Sprint Sequence                                        Sprint Goal  \\\n",
       "0            5514  (1) Finalise and publish changes in response t...   \n",
       "1            5495  (1) FLOW 69-70; (2) Clouding Atlassian Impleme...   \n",
       "\n",
       "  Sprint Auto Start Stop  \n",
       "0                  false  \n",
       "1                  false  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Sprints\n",
    "\n",
    "from IPython.display import display\n",
    "from dateutil import parser\n",
    "from pandas.core.dtypes.dtypes import DatetimeTZDtype\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "    display(\"Base data frame not loaded\") \n",
    "else:\n",
    "    df = goldenDF.copy(deep = True)\n",
    "    df = df[[\"Id\", \"Key\", \"Sprint\"]]\n",
    "    df = df[~df[\"Sprint\"].isna()]\n",
    "\n",
    "    if df is None or len(df.index) == 0:\t\n",
    "        display(\"No results\")\n",
    "    else:\t\t\n",
    "        df = df.explode(\"Sprint\")\n",
    "        df = df.expand(\"Sprint\")\n",
    "\n",
    "        if \"Sprint Start Date\" not in df.columns.values:\n",
    "            # Server instance not cloud \n",
    "            def fixSprint(s):\n",
    "                try:\n",
    "                    s = (s.split('[', 1)[1])[:-1]\n",
    "                    res = []\n",
    "                    for sub in s.split(','):\n",
    "                        if '=' in sub:\n",
    "                            res.append(map(str.strip, sub.split('=', 1)))\n",
    "                    return dict(res)\n",
    "                except: \n",
    "                    return None\n",
    "            df[\"Sprint\"] = df[\"Sprint\"].apply (fixSprint)\n",
    "            df = df.expand(\"Sprint\")\n",
    "\n",
    "            def fixDate(s):\n",
    "                try:\n",
    "                    return parser.isoparse(s)\n",
    "                except:\n",
    "                    return None\n",
    "            df[\"Sprint Start Date\"] = df[\"Sprint Start Date\"].apply(fixDate)\n",
    "            df[\"Sprint End Date\"] = df[\"Sprint End Date\"].apply(fixDate)\n",
    "            df[\"Sprint Complete Date\"] = df[\"Sprint Complete Date\"].apply(fixDate)\n",
    "            \n",
    "        df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "\n",
    "        df[\"Sprint Start Date\"] = df[\"Sprint Start Date\"].astype(DatetimeTZDtype(\"ns\", \"+10:00\"))\n",
    "        df[\"Sprint End Date\"] = df[\"Sprint End Date\"].astype(DatetimeTZDtype(\"ns\", \"+10:00\"))\n",
    "        df[\"Sprint Complete Date\"] = df[\"Sprint Complete Date\"].astype(DatetimeTZDtype(\"ns\", \"+10:00\"))\n",
    "        \n",
    "        display(df.dtypes)\n",
    "        display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                           Int64\n",
       "Key                                 string[python]\n",
       "Attachment Id                                Int64\n",
       "Attachment Filename                 string[python]\n",
       "Attachment Created       datetime64[ns, UTC+10:00]\n",
       "Attachment Mime Type                string[python]\n",
       "Attachment Size                            float64\n",
       "Attachment Thumbnail                string[python]\n",
       "Attachment Content                  string[python]\n",
       "Attachment Author Key               string[python]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Attachments\n",
    "\n",
    "from IPython.display import display\n",
    "from pandas.core.dtypes.dtypes import DatetimeTZDtype\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "    display(\"Base data frame not loaded\") \n",
    "else:\n",
    "    df = goldenDF.copy(deep = True)\n",
    "    df = df[[\"Id\", \"Key\", \"Attachment\"]]\n",
    "    df = df[df[\"Attachment\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "    if df is None or len(df.index) == 0:\t\n",
    "        display(\"No results\")\n",
    "    else:\n",
    "        df = df.explode(\"Attachment\")\n",
    "        df = df.expand(\"Attachment\", [\"id\", \"filename\", \"created\", \"mimeType\", \"size\", \"thumbnail\", \"content\", \"author\"])\n",
    "        df = df.expand(\"Attachment Author\", [\"key\"])\n",
    "\n",
    "        df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "        df[\"Attachment Id\"] = df[\"Attachment Id\"].astype('Int64')\n",
    "        df[\"Attachment Size\"] = df[\"Attachment Size\"].astype('float64')\n",
    "        df[\"Attachment Created\"] = df[\"Attachment Created\"].astype(DatetimeTZDtype(\"ns\", \"+10:00\"))\n",
    "\n",
    "        display(df.dtypes)\n",
    "        #display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                             Int64\n",
       "Key                   string[python]\n",
       "Fix Version/s Id               Int64\n",
       "Fix Version/s Name    string[python]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! Versions\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "if 'goldenDF' not in globals() or goldenDF is None: \n",
    "    display(\"Base data frame not loaded\") \n",
    "else:\n",
    "    df = goldenDF.copy(deep = True)\n",
    "    df = df[[\"Id\", \"Key\", \"Fix Version/s\"]]\n",
    "    df = df[df[\"Fix Version/s\"].map(lambda d: len(d)) > 0]\n",
    "\n",
    "    if df is None or len(df.index) == 0:\t\n",
    "        display(\"No results\")\n",
    "    else:\n",
    "        df = df.explode(\"Fix Version/s\")\n",
    "        df = df.expand(\"Fix Version/s\", [\"id\", \"name\"])\n",
    "\n",
    "        df = df.sentence_case_columns().convert_dtypes().infer_objects().reset_index(drop=True)\n",
    "        df[\"Fix Version/s Id\"] = df[\"Fix Version/s Id\"].astype('Int64')\n",
    "\n",
    "        display(df.dtypes)\n",
    "        #display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
